{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31ffb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import pickle as pkl\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a779f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold = pd.read_csv('data/train_fold.csv', dtype={'text_id' : 'object'})\n",
    "dict_ = {}\n",
    "for i in range(len(train_fold)):\n",
    "    dict_[str(train_fold.loc[i, 'text_id'])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b946bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohesion : 0.47327529420322045\n",
      "syntax : 0.4370771137258687\n",
      "vocabulary : 0.4058784493645005\n",
      "phraseology : 0.44559806140272423\n",
      "grammar : 0.4635767862220229\n",
      "conventions : 0.43840399747582937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "eval_list = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "coefs = []\n",
    "\n",
    "df_sum = pd.DataFrame([])\n",
    "for k in eval_list:\n",
    "    data = pd.DataFrame([])\n",
    "    for idx, i in enumerate(os.listdir('predict')):   # 각 모델\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join('predict', i, 'oof_data.csv'), index_col=0)\n",
    "            data['{}'.format(i)] = df[k]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "#     for i in range(1, 13):\n",
    "#         with open(\"predict/oof_df.pkl ({})/oof_df.pkl\".format(i), \"rb\") as f:\n",
    "#             df = pkl.load(f)\n",
    "#         dict__ = []\n",
    "#         for j in range(len(df)):\n",
    "#             try:\n",
    "#                 l = dict_[df.loc[j, 'text_id']]\n",
    "#                 dict__.append(l)\n",
    "#             except:\n",
    "#                 ValueError()\n",
    "#         df['idx'] = dict__\n",
    "#         df.sort_values(by='idx', inplace=True)\n",
    "#         df.reset_index(drop=True, inplace=True)\n",
    "#         data[i] = df['pred_'+k]\n",
    "        \n",
    "    train = data.values\n",
    "    ans = pd.read_csv('data/train_fold.csv')[k].values\n",
    "    linear = LinearRegression()\n",
    "    linear.fit(train, ans)\n",
    "    prediction = linear.predict(train)\n",
    "\n",
    "    print('{} : {}'.format(k, mean_squared_error(prediction, ans, squared=False)))\n",
    "    coefs.append(linear.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfd23024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.02468827,  0.01437969, -0.16997332, -0.06378136,  0.09925593,\n",
       "        -0.14434502,  0.25566551,  0.04314837, -0.00287905,  0.00157988,\n",
       "         0.21722764,  0.17301293,  0.01158325,  0.37524524,  0.2222383 ,\n",
       "         0.02657244, -0.17524487,  0.12026351]),\n",
       " array([-0.00554599, -0.09864255, -0.03283034,  0.01100232,  0.08877053,\n",
       "        -0.44237157,  0.42066285,  0.14919479, -0.05189426, -0.02122462,\n",
       "         0.31019634,  0.13965195,  0.08109633,  0.22936185,  0.20586317,\n",
       "        -0.03187159, -0.0620047 ,  0.09124441]),\n",
       " array([ 0.01133957,  0.00102318,  0.2249395 ,  0.10911379,  0.11591557,\n",
       "        -0.12086344,  0.14706209, -0.07191999, -0.02380568, -0.13426628,\n",
       "         0.1688741 ,  0.02553323,  0.11637734,  0.07900849,  0.2870512 ,\n",
       "        -0.0325324 , -0.05061934,  0.13387843]),\n",
       " array([-0.01358336,  0.14455209, -0.00932055,  0.06291627,  0.11673717,\n",
       "        -0.21839524,  0.21565667, -0.04944162,  0.0283303 ,  0.11075765,\n",
       "         0.29320124, -0.27259406,  0.04855632,  0.15755496,  0.2618735 ,\n",
       "        -0.07523585,  0.01261131,  0.17331544]),\n",
       " array([-0.00860003,  0.30674581, -0.00746757,  0.02489634,  0.00230137,\n",
       "         0.04351409,  0.04630428, -0.06192136, -0.01797251,  0.13802037,\n",
       "         0.00446793,  0.03149022, -0.01638602,  0.24966105,  0.16941562,\n",
       "        -0.04414346,  0.03326759,  0.07732592]),\n",
       " array([ 0.11687953,  0.15729717,  0.09830002, -0.06178662,  0.11873099,\n",
       "        -0.00739904,  0.06700708, -0.00775167, -0.04749936,  0.01383405,\n",
       "        -0.0420566 , -0.06458973,  0.02219164,  0.12697234,  0.20218924,\n",
       "         0.14047482,  0.20604031, -0.05485291])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(len(df_sum) * .8)\n",
    "train1 = df_sum[:length][['cohesion', 'cohesion_mean', 'cohesion_median']].values\n",
    "ans1 = train_fold['cohesion'][:length].values\n",
    "train2 = df_sum[length:][['cohesion', 'cohesion_mean', 'cohesion_median']].values\n",
    "ans2 = train_fold['cohesion'][length:].values\n",
    "local_score = 0.4713640057952513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_sum[['syntax', 'syntax_mean', 'syntax_median']].values\n",
    "ans = train_fold['syntax'].values\n",
    "\n",
    "linear = LinearRegression()\n",
    "linear.fit(train, ans)\n",
    "prediction = linear.predict(train)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(prediction, ans, squared=False))\n",
    "linear.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     coefs.append(linear.coef_)\n",
    "save = []\n",
    "save2 = []\n",
    "def objective(trial: Trial) -> float:\n",
    "\n",
    "#     params_lgb = {\n",
    "#         \"random_state\": 42,\n",
    "#         \"verbosity\": 1,\n",
    "#         \"learning_rate\": trial.suggest_float('lr', .05, .1),\n",
    "#         \"n_estimators\": 1000,\n",
    "#         \"objective\": \"regression\",\n",
    "#         \"metric\": \"rmse\",\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 3e-5),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 9e-2),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "# #             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "#         \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "#         'num_boost_round' : trial.suggest_int(\"max_bin\", 100, 1000)\n",
    "#     }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    model.fit(train1, ans1, eval_set=[(train2, ans2)], verbose=0)\n",
    "    pred1 = model.predict(train1)\n",
    "    pred2 = model.predict(train2)\n",
    "    loss1 = mean_squared_error(pred1, ans1) ** .5        # train\n",
    "    loss2 = mean_squared_error(pred2, ans2) ** .5        # valid\n",
    "\n",
    "    if (local_score > loss2): \n",
    "        save.append(loss1)\n",
    "        save2.append(loss2)\n",
    "\n",
    "    return loss2\n",
    "\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"lgbm_parameter_opt\",\n",
    "    direction=\"minimize\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(\"Best Score:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n",
    "print('save : ', save)\n",
    "print('save2 : ', save2)\n",
    "print('local_score', local_score)\n",
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6534075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = deepcopy(data)\n",
    "ans = pd.read_csv('data/train_fold.csv')[k].values\n",
    "train_data = data[:3500]\n",
    "valid_data = data[3500:]\n",
    "train_ans = ans[:3500]\n",
    "valid_ans = ans[3500:]\n",
    "train_ans = np.expand_dims(train_ans, axis=1)\n",
    "valid_ans = np.expand_dims(valid_ans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c5764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc106a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af58926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab824be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d9c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16241fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tqdm import tqdm \n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349c06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv('data/train_fold.csv')\n",
    "index = answer['fold']\n",
    "list_ = ['sentences_count',\n",
    "'spaces_count',\n",
    "'chars_excl_spaces_count',\n",
    "'punctuations_count',\n",
    "'count_words',\n",
    "'duplicates_count',\n",
    "'stop_words_count',\n",
    "'noun_phrase_count',]\n",
    "\n",
    "eval_list = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "cnt = 0\n",
    "for k in eval_list:\n",
    "    for j in range(4):\n",
    "        \n",
    "        train_data = pd.DataFrame([])\n",
    "        valid_data = pd.DataFrame([])\n",
    "\n",
    "        train_label = answer[k][index != j]\n",
    "        valid_label = answer[k][index == j]\n",
    "\n",
    "        for idx, i in enumerate(os.listdir('predict')):\n",
    "            path = os.path.join('predict', i, 'oof_data.csv')\n",
    "            local_data = pd.read_csv(path, index_col=0)\n",
    "            train_feature = local_data[index != j][k]\n",
    "            valid_feature = local_data[index == j][k]\n",
    "            train_data['{}'.format(idx)] = train_feature\n",
    "            valid_data['{}'.format(idx)] = valid_feature\n",
    "\n",
    "        for i in list_:\n",
    "            appending = answer[i]\n",
    "            train_appending = appending[index != j]\n",
    "            valid_appending = appending[index == j]\n",
    "            train_data[i] = train_appending\n",
    "            valid_data[i] = valid_appending\n",
    "            \n",
    "        for i in list_:\n",
    "            if i == 'chars_excl_spaces_count':\n",
    "                continue\n",
    "            else:\n",
    "                train_data[i] = train_data[i] / train_data['chars_excl_spaces_count']\n",
    "\n",
    "        numeric_features = []                      ########################################## HAVE TO BE CHANGE\n",
    "        numeric_transformer = StandardScaler()\n",
    "        categorical_features = ['0', '1', '2', '3', '4', '5', '6']\n",
    "        # categorical_transformer = OneHotEncoder(categories='auto') # categories='auto' : just for ignoring warning messages\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers = [ ('num', numeric_transformer, numeric_features),\n",
    "                ('passthrough', 'passthrough', categorical_features)])\n",
    "        preprocessor_pipe = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "        \n",
    "        \n",
    "        train_data = preprocessor_pipe.fit_transform(train_data)\n",
    "        valid_data = preprocessor_pipe.fit_transform(valid_data)\n",
    "        \n",
    "        def objective(trial: Trial) -> float:\n",
    "\n",
    "            params_lgb = {\n",
    "                \"random_state\": 42,\n",
    "                \"verbosity\": -1,\n",
    "                \"learning_rate\": trial.suggest_float('lr', .05, .1),\n",
    "                \"n_estimators\": 1000,\n",
    "                \"objective\": \"multiclass\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 3e-5),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 9e-2),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "#                 \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "                \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "                \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "                'num_boost_round' : trial.suggest_int(\"max_bin\", 100, 1000)\n",
    "            }\n",
    "            model = LGBMRegressor(**params_lgb)\n",
    "\n",
    "            model.fit(train_data, train_label, eval_set=[(train_data, train_label), (valid_data, valid_label)], early_stopping_rounds=100, verbose=False)\n",
    "            pred = model.predict(valid_data)\n",
    "            loss = mean_squared_error(pred, valid_label) ** .5\n",
    "\n",
    "            return loss\n",
    "        sampler = TPESampler(seed=42)\n",
    "        study = optuna.create_study(\n",
    "            study_name=\"lgbm_parameter_opt\",\n",
    "            direction=\"minimize\",\n",
    "            sampler=sampler,\n",
    "        )\n",
    "        study.optimize(objective, n_trials=100)\n",
    "        print(\"Best Score:\", study.best_value)\n",
    "        print(\"Best trial:\", study.best_trial.params)\n",
    "        \n",
    "        print(study.best_params)\n",
    "        \n",
    "        model = LGBMRegressor(**study.best_params)\n",
    "        model.fit(train_data, train_label)\n",
    "        joblib.dump(model, 'lgb/lgb_{}.pkl'.format(cnt))\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2552e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save({'model' : final}, 'final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a783f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list___ = []\n",
    "for i in range(0, 24, 4):\n",
    "    list_ = final_[i:i+4]\n",
    "    k = np.array(list_).sum() / 4\n",
    "    list___.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9492c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list___).sum() / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c25b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = model.predict(valid_feature)\n",
    "ans = valid_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_squared_error(train_data[:, 0], train_label, squared=False)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
